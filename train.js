const tf = require("@tensorflow/tfjs-node");
const { loadImagesFromTrainingData } = require("./training_dataset");
const { CHARACTERS } = require("./train_constants");

/**
 * **Modellt betan√≠tja a kiv√°lasztott dataset alapj√°n**
 */
async function trainModel() {
    console.log("üì• Bet√∂lt√©s: Training dataset...");
    let dataset = await loadImagesFromTrainingData();  

    if (dataset.length === 0) {
        console.log("‚ö†Ô∏è Nincs el√©rhet≈ë adat a tan√≠t√°shoz.");
        return;
    }

    const images = dataset.map(d => d.tensor);
    const labels = dataset.map(d => d.label);

    const xTrain = tf.stack(images);
    const yTrain = tf.oneHot(tf.tensor1d(labels, "int32"), CHARACTERS.length);

    // **Model fel√©p√≠t√©se**
    const model = tf.sequential();
    model.add(tf.layers.conv2d({ inputShape: [28, 28, 1], filters: 32, kernelSize: 3, activation: "relu" }));
    model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
    model.add(tf.layers.flatten());
    model.add(tf.layers.dense({ units: 128, activation: "relu" }));
    model.add(tf.layers.dense({ units: CHARACTERS.length, activation: "softmax" }));

    model.compile({
        optimizer: "adam",
        loss: "categoricalCrossentropy",
        metrics: ["accuracy"]
    });

    console.log("üöÄ Kezd≈ëdik a tan√≠t√°s...");
    await model.fit(xTrain, yTrain, { epochs: 5 });

    console.log("‚úÖ Modell betan√≠tva!");

    try {
        await model.save("file://./model");
        console.log("üìÇ √öj modell elmentve!");

    } catch (error) {
        console.error("‚ùå Hiba a modell ment√©se sor√°n, a training_data NEM lett √°thelyezve!", error);
    }
}

trainModel();
